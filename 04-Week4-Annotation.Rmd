# Variant Annotation

In the - for now - final Galaxy workflow step for analyzing our patient, we are going to annotate all our filtered variants to determine the severity of the variations we determined last time with the `LoFreq` tool. This involves comparing all our variants against a number of databases containing *annotation data* for known variants. We will use our filtered `VCF`-file resulting from LoFreq so we need to upload our newly created VCF file to Galaxy. Make sure that Galaxy recognizes the file type by selecting the correct file type when uploading or change it afterwards using the *Edit attributes* button.

```{r, echo=FALSE}
knitr::include_graphics("images/upload.png")
```

## SnpEff and SnpSift

There are multiple methods of annotating found variants. Most of these will require extra data to predict the effect of a variant or to compare it with a known set of variants. Here we use a set of tools that does both types of annotation. See for further details and a manual the [Github documentation](http://pcingola.github.io/SnpEff/).

* **`SnpEff`**: *is a variant annotation and effect prediction tool. It annotates and predicts the effects of genetic variants (such as amino acid changes)*
* **`SnpSift`**: *is a toolbox that allows you to filter and manipulate annotated files.*
  - actually, this tool also annotates variants using a variety of data sources, for which we will use it.
  
Both tools are available in Galaxy with numerous sub-tools depending on the task that you want to do. To get the most information for each variant, we will perform three annotation *runs*:

**Step 1**: Using SnpEff to annotate variants using the `GRCh38.86` database adding information related to the gene, transcript and protein that are affected by this variant. This results in a lot of extra data that is all documented in the changed VCF header. 

For example, given the following variant as input:

> `*chr1	237550644	.	C	A	91.0	PASS	DP=578;AF=0.017301;SB=1;DP4=252,316,5,5*`

This is the result after SnpEff:

> `*chr1	237550644	.	C	A	91.0	PASS	DP=578;AF=0.017301;SB=1;DP4=252,316,5,5*;**ANN**=A|missense_variant|MODERATE|RYR2|ENSG00000198626|transcript|ENST00000366574.6|protein_coding|27/105|c.3167C>A|p.Thr1056Lys|3484/16562|3167/14904|1056/4967||,A|missense_variant|MODERATE|RYR2|ENSG00000198626|transcript|ENST00000360064.7|protein_coding|25/103|c.3119C>A|p.Thr1040Lys|3119/14850|3119/14850|1040/4949||WARNING_TRANSCRIPT_NO_START_CODON,A|downstream_gene_variant|MODIFIER|SNORA25|ENSG00000252290|transcript|ENST00000516481.1|snoRNA||n.*4396G>T|||||4396|`

All details are added in the `ANN` field. See the description in the VCF header for a field-by-field explanation of the values. 

**Running SnpEff**:

* Select the `SnpEff Variant effect and annotation` tool from the `Variant Calling` tool menu in Galaxy. 
* Select the uploaded VCF file containing the variants filtered for the cardiopanel genes. 
* Check if the by default selected `GRCh38.86` *Genome Source* is selected. 
* All other settings can be left default, execute the tool.

The result consists of two files: an annotated VCF file and a web-report on all the variants and their predicted effects.
  
**Step 2**: Adding `dbSnp` entries using `SnpSift`. The [dbSnp](https://www.ncbi.nlm.nih.gov/snp/) database contains information on known variants. The version that also includes clinical significance (combining the ClinVar database) is available for the SnpSift tool in Galaxy. 

**Running SnpSift for dbsnp**: 

* SnpSift requires the `dbSnp` database to be available in your history:
  - In Galaxy, go to `Shared Data` (top menu) --> `Data Libraries` --> `dbSnp` library
  - Select both files shown there and use the `Add to history` --> `as datasets` option to get them in your own history
* Select the `SnpSift Annotate SNPs from dbSnp` tool from the `Variant Calling` tool menu in Galaxy.
  - **Note**: this is a different tool from the `dbNSFP` database, see step #3 below.
* Select the output VCF file created by SnpEff in step #1 as the `Variant input file`.
* Select the `dbSnp_clinvar.vcf.gz` file as the `VCF File with ID field annotated`.
* For `Fields to annotate` select the `Add also INFO fields` option and execute the tool.

This tool adds annotations in two columns. First, the `ID` column will describe the `dbSnp` ID (rs number) that can be used to look up the variant. Second, the `INFO` column is expanded with (a lot of) extra information if the variant is known. For instance, the ClinVar data might report on diseases the variant is related to, such as:

> `CLNDN=Cardiovascular_phenotype|Charcot-Marie-Tooth_disease|Lipoatrophy_with_Diabetes,_Hepatic_Steatosis,_Hypertrophic_Cardiomyopathy,_and_Leukomelanodermic_Papules`

**Step 3**: Annotating using the `dbNSFP` database and SnpSift. The dbNSFP database is a huge collection (over 300GB of text files) of annotation sources combined into a single database. The SnpSift tool can compare our variants with known variants from all of these annotation sources and - like the first few steps - adds them to our VCF file. As you can expect, our VCF file will become very large and most likely unreadable. Therefore, we re-use the VCF file gained from step #1 instead of the VCF file from SnpSift in step #2. We can later combine the data after parsing both files separately.

**Running SnpSift for dbNSFP**:

* Select the `SnpSift dbNSFP` tool from the `Variant Calling` tool menu in Galaxy.
* Use the VCF file from step #1 as input
* Select the locally available `GRCh38 dbNSFP4.3c` Genome database

Note that the tool description lists output not available for selection, we will look into the specifics of all selected databases later on.


<!--

Commandline SnpEff and SnpSift for 2.1.2

Step #1 SnpEff

cd /local-fs/datasets/dbNSFP/snpEff/;
java -jar snpEff.jar ann GRCh38.105 /homes/marcelk/Development/NGS-Genetics/solution/bed_variants.vcf > /homes/marcelk/Development/NGS-Genetics/solution/bed_annotation.vcf
----------

Step #2 SnpSift - dbSnp

/local-fs/datasets/dbNSFP/snpEff/scripts/snpSift annotate /local-fs/datasets/dbNSFP/snpEff/data/clinvar.vcf.gz /homes/marcelk/Development/NGS-Genetics/solution/bed_variants.vcf > /homes/marcelk/Development/NGS-Genetics/solution/bed_annotation.vcf
----------

Step #3 SnpSift - dbNSFP with all options:

/local-fs/datasets/dbNSFP/snpEff/scripts/snpSift DbNsfp -db /data/datasets/dbNSFP/snpEff/data/dbNSFP4.3c.txt.gz /homes/marcelk/Development/NGS-Genetics/solution/bed_variants.vcf > /homes/marcelk/Development/NGS-Genetics/solution/bed_annotation.vcf
----------

-->


### Assignment

* Create a table in your report where you summarize the added annotation data (very!) briefly;
    * The database where the data comes from
    * The result or value (is it an identifier, a percentage, etc.). Section 7.2 below contains links to sources for some of the most important annotation sources.
    * **Hint**: you can add formatted tables in markdown with some syntax which is easiest generated at [https://www.tablesgenerator.com](www.tablesgenerator.com/markdown_tables)


## Programming Assignment; Analyzing Variant Annotation

Given the possibly hundreds of annotated variants with data from multiple data sources, it's time to do one last *filtering* on the data to come up with a list of variants of which we can say, with some certainty, that they are related to the condition. As with the VCF-filter tool that we've written, here too will we check each line and decide if it is a variant worth reporting on. Whether we want to keep a variant or not depends on the annotation added by SnpEff and it is your task to come up with an approach for **combining** data from these data sources to *rank* the annotated variants.

From all the annotation columns we need to get - at least - the following data for each variant. 
Note: for some of these data sources only a few of your variants are actually annotated.
Note: the list below links to the SnpEff documentation regarding this value; read these documents to at least *know* what they mean.

**TODO**: add descriptions to important fields and the location where they can be found

### Assignment 10; Data Preparation

This programming assignment asks to take another good look at the data, but now in R to see if everything is in a suitable format to eventually sort the data and extract a top-set of variants related to the condition.

* Load the data into R using your function of choice. Note that choosing the proper separator character is important.
* Print the structure of the resulting data-frame and inspect all columns on their data type.
* Columns that contain mixed data, in a single value, should be converted such that sorting is possible (look at the `LJB2_PolyPhen2_*` columns)


### Assignment 11; Finding Variants of Interest

Given the knowledge we have on the data stored in the data-frame, we can now formulate questions to this data to find a set of variants which are most likely linked to the cardiomyopathy condition. This condition cannot be identified by a single variant but is often caused by several variants and the combination not only determines *if* someone suffers from cardiomyopathy but also how *badly* their condition is. 

The physisian who diagnoses patients uses the genetic information of the found variants as one of the sources for confirming the condition. However, presenting a list of 100+ variant positions with a list of numbers from some tools is not how that works in practice; we need to present a short, ordered list of variants that can be related to the condition. 

Next, define your own sorting, filtering, selecting, etc. procedure to filter and order a top-list of variants that you'd present as aid to a diagnoses. For instance, you might have a variant that had a hit in the Clinvar database which directly links it to cardiomyopathy, this should probably be somewhere around the top of your list. Again, look at the output description that you've written earlier to come up with combination(s) of values. There is no golden standard for selecting these variants so it is very important to properly document and argument your decisions.

As an end product for this step you are expected to include a nice table including at least 10 variants in your report that contains all relevant information for each of them, i.e. the chromomsome, position, reference and variant nucleotides, gene name and all relevant scores.

For all of your variants, try to (briefly!) answer the following questions for each variant:
* Can you find a link between cardiomyopathy and the variant?
* What is the effect of the variant?
* Is it validated?
* Are there scientific studies supporting the evidence?
* What does the score indicate?
* What else can you find about the variant?

You can use the following online sources amongst others:  
* http://www.ncbi.nlm.nih.gov/snp/  
* http://www.ncbi.nlm.nih.gov/variation/tools/1000genomes/  
* http://www.ncbi.nlm.nih.gov/projects/SNP/

## Galaxy Workflow

Now that we have completed our analysis steps we can create a **Galaxy workflow**. In this workflow we will combine all the tools that we have used in Galaxy (FastQ files --> SnpEff/SnpSift annotated output) so that when we receive new patient data in the future we can analyze that dataset with a single click!

There are many [online resources](https://galaxyproject.org/learn/advanced-workflow/) giving instructions and examples for creating Galaxy workflows, use these resources to create a workflow including all used analysis tools. Note that you can convert Galaxy histories into workflow(s), which saves a lot of time with configuring all the tools from that workfow.

Once you have a workflow, make sure it is shared with your project partner and create a screenshot of it for your report (try to fit all tools in a single image).


**Note**; this assignment has a very low priority and should be done once you are satisfied with all other parts of your work! At the bare minimum, open your last history (including SnpEff/SnpSift) and explore/ play with the `Extract Workflow` option.

<!--
## Project Deadlines

There are multiple deadlines for finalizing this project:
* Programming assignments: all graded deliverables (7, 8, 9 and 12) *must* be available on your BitBucket repository on **Friday November the 3rd, 24.00h** (even if incomplete, make sure that the latest version(s) are available).
* Journal/'report': the OneNote documents are downloaded for grading on **Thursday November the 16th** and the final grade is available on Friday the 17th of November. 
-->

## Comparative Genomics

With the complete analysis nicely packaged into a single workflow, one thing that we can use it for is to do *comparative genomics*. This term contains many different types of comparisons and is described on Wikipedia as 

> *Comparative genomics is a field of biological research in which the genomic features of different organisms are compared.*

These features can be of many types and in our case they are the variants. A simple tool is available in Galaxy called *VCF-VCFintersect* that performs either *intersection* or *union* on two VCF datasets containing variant data. This tool compares two VCF files and retains either the shared variants (intersection) or all variants combined (union) as shown in the diagram below.

```{r, echo=FALSE}
knitr::include_graphics("images/intersect_union.png")
```


**Assignment**

* Process another patient sample (use a new history) by running your complete workflow. 
    + Note that you have to filter the resulting SnpEff output (which contains the same data as the VCF file appended with annotation data) with the BED-data. Alternatively, you can stop after the Varscan tool, download the VCF file, filter this using the BED-data and re-upload the filtered VCF file before continuing with SnpEff
* Calculate the following three statistics:
    + The number of variants unique to patient 1
    + The number of variants unique to patient 2
    + The number of variants found in both patients
* Create a VENN-diagram (like the image above) displaying these numbers.

## Galaxy Data Cleanup

As a final closing assignment we ask you to clean up the Galaxy histories to save some space because it is difficult for the admin(s) to perform this cleaning for you. Once all products are finished, please consider removing all large files from your history, such as the outputs of the trimming (Trimmomatic), mapping (BWA), duplicate read marking (MarkDuplicates) and the pileup steps (Mpileup). For the large files, please make sure that you *also* click the *Permanently remove it from disk* link.

First click on the `deleted` link at the top of your history<br/>
<img src="pics/show_deleted.png"><br/>
Then, find the deleted elements and click on the permanently remove link.<br/>
<img src="pics/perm_delete.png">
